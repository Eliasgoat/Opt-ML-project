{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32cbed19-5d98-4b1b-bc20-0e381f583700",
   "metadata": {},
   "source": [
    "# Final Runs for the MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75b1c4d-90ad-4872-b59b-4a6452b3ceb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from structure import run_experiments, make_optimizer_config\n",
    "\n",
    "# === Step 1 : grid search ===\n",
    "optim_names = [\"PGD\", \"SGD\", \"Nesterov\",\"GD\", \"PartialGD\", \"Momentum\", \"RMSprop\", \"Adam\"]\n",
    "lr_grid = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
    "dataset_list = [\"SVHN\", \"CIFAR10\"]\n",
    "model_list = [{\"name\": \"MLP\"}]\n",
    "\n",
    "optim_configs = []\n",
    "for name in optim_names:\n",
    "    for lr in lr_grid:\n",
    "        if name in [\"Momentum\", \"Nesterov\"]:\n",
    "            optim_configs.append(make_optimizer_config(name, lr=lr, momentum=0.9))\n",
    "        elif name == \"PartialGD\":\n",
    "            optim_configs.append(make_optimizer_config(name, lr=lr, update_fraction=0.5))\n",
    "        elif name == \"PGD\":\n",
    "            optim_configs.append(make_optimizer_config(name, lr=lr))\n",
    "        else:\n",
    "            optim_configs.append(make_optimizer_config(name, lr=lr))\n",
    "# !export USE_GPU=true\n",
    "# === Run the grid scan ===\n",
    "results_path = \"data/grid_scan_MLP.json\"\n",
    "run_experiments(\n",
    "    datasets=dataset_list,\n",
    "    models=model_list,\n",
    "    optimizers_with_params=optim_configs,\n",
    "    epochs=30,\n",
    "    save_results=True,\n",
    "    save_path=results_path\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bc8c54-ade5-4b02-ab02-12fc45deecd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filename = \"data/grid_scan_MLP.json\"\n",
    "\n",
    "# === Step 2 : extract the best lr and epochs ===\n",
    "with open(filename, \"r\") as f:\n",
    "    all_results = json.load(f)\n",
    "\n",
    "best_configs = {}\n",
    "for r in all_results:\n",
    "    key = (r[\"dataset\"], r[\"optimizer\"])\n",
    "    test_losses = r.get(\"test_losses\", [])\n",
    "    if not test_losses:\n",
    "        continue\n",
    "    min_epoch = int(np.argmin(test_losses))\n",
    "    min_loss = test_losses[min_epoch]\n",
    "    if key not in best_configs or min_loss < min(best_configs[key][\"test_losses\"]):\n",
    "        best_configs[key] = {\n",
    "            \"dataset\": r[\"dataset\"],\n",
    "            \"optimizer\": r[\"optimizer\"],\n",
    "            \"params\": r[\"optimizer_params\"],\n",
    "            \"best_epoch\": min_epoch,\n",
    "            \"min_loss\": min_loss,\n",
    "            \"test_losses\": test_losses  # âœ… Ajout nÃ©cessaire\n",
    "\n",
    "        }\n",
    "\n",
    "# === Step 3: rerun the best runs with optimal lr and adjusted epoch ===\n",
    "for (dataset, optim), config in best_configs.items():\n",
    "    lr = config[\"params\"][\"lr\"]\n",
    "    best_epoch = config[\"best_epoch\"]\n",
    "    adjusted_epoch = best_epoch \n",
    "\n",
    "    print(f\"\\nðŸ” Running {optim} on {dataset} with lr={lr:.5f} for {adjusted_epoch} epochs\")\n",
    "\n",
    "    run_experiments(\n",
    "        datasets=[dataset],\n",
    "        models=model_list,\n",
    "        optimizers_with_params=[{\n",
    "            \"name\": optim,\n",
    "            \"params\": config[\"params\"]\n",
    "        }],\n",
    "        epochs=adjusted_epoch,\n",
    "        avg_over_seeds=True,\n",
    "        seeds=[0, 1, 2, 3, 4],\n",
    "        save_results=True,\n",
    "        save_path=f\"Data/MLP_best_{dataset}_{optim}.json\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a928e5-e156-4f5d-a688-5d53f560065b",
   "metadata": {},
   "source": [
    "# Merge the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4457da77-a5a8-477c-a48f-c3840c0ecf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def merge_mlp_best_results(data_dir=\"data\"):\n",
    "    \"\"\"\n",
    "    Merges all files MLP_best_{dataset}_{optimizer}.json into:\n",
    "    - data/merged_MLP_CIFAR10.json\n",
    "    - data/merged_MLP_SVHN.json\n",
    "    \"\"\"\n",
    "    merged = {\"CIFAR10\": [], \"SVHN\": []}\n",
    "\n",
    "    for filename in os.listdir(data_dir):\n",
    "        if filename.startswith(\"MLP_best_\") and filename.endswith(\".json\"):\n",
    "            if \"CIFAR10\" in filename:\n",
    "                dataset = \"CIFAR10\"\n",
    "            elif \"SVHN\" in filename:\n",
    "                dataset = \"SVHN\"\n",
    "            else:\n",
    "                continue  # ignore the datasets\n",
    "\n",
    "            filepath = os.path.join(data_dir, filename)\n",
    "            with open(filepath, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "                if isinstance(data, list):\n",
    "                    merged[dataset].extend(data)\n",
    "                else:\n",
    "                    merged[dataset].append(data)\n",
    "\n",
    "    # Final save\n",
    "    for dataset in merged:\n",
    "        output_file = os.path.join(data_dir, f\"merged_MLP_{dataset}.json\")\n",
    "        with open(output_file, \"w\") as f_out:\n",
    "            json.dump(merged[dataset], f_out, indent=2)\n",
    "        print(f\"âœ… Fusion terminÃ©e pour {dataset}: {output_file}\")\n",
    "\n",
    "# Direct execution\n",
    "merge_mlp_best_results()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
